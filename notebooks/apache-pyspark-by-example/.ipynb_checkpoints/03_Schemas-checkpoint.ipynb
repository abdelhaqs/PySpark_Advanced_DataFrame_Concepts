{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8qf-TmnsBgXd"
   },
   "source": [
    "# Schemas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FEuEkV0BlzAD"
   },
   "source": [
    "## Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sdOOq4twHN1K"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://d7d62c766499:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7712d0b83010>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate() \n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0ysUlfFrN5OD"
   },
   "source": [
    "## Downloading and preprocessing Chicago's Reported Crime Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FDtw5Hy3N-pV"
   },
   "outputs": [],
   "source": [
    "#!wget https://data.cityofchicago.org/api/views/ijzp-q8t2/rows.csv?accessType=DOWNLOAD\n",
    "#!ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_timestamp,col,lit\n",
    "path =\"../datasets/sparkbyexamples/police-stations.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc = spark.read.csv(path,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: string (nullable = true)\n",
      " |-- Case Number: string (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Block: string (nullable = true)\n",
      " |-- IUCR: string (nullable = true)\n",
      " |-- Primary Type: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Location Description: string (nullable = true)\n",
      " |-- Arrest: string (nullable = true)\n",
      " |-- Domestic: string (nullable = true)\n",
      " |-- Beat: string (nullable = true)\n",
      " |-- District: string (nullable = true)\n",
      " |-- Ward: string (nullable = true)\n",
      " |-- Community Area: string (nullable = true)\n",
      " |-- FBI Code: string (nullable = true)\n",
      " |-- X Coordinate: string (nullable = true)\n",
      " |-- Y Coordinate: string (nullable = true)\n",
      " |-- Year: string (nullable = true)\n",
      " |-- Updated On: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rc.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9-1cK0nPNS95"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ID', 'string'),\n",
       " ('Case Number', 'string'),\n",
       " ('Date', 'timestamp'),\n",
       " ('Block', 'string'),\n",
       " ('IUCR', 'string'),\n",
       " ('Primary Type', 'string'),\n",
       " ('Description', 'string'),\n",
       " ('Location Description', 'string'),\n",
       " ('Arrest', 'string'),\n",
       " ('Domestic', 'string'),\n",
       " ('Beat', 'string'),\n",
       " ('District', 'string'),\n",
       " ('Ward', 'string'),\n",
       " ('Community Area', 'string'),\n",
       " ('FBI Code', 'string'),\n",
       " ('X Coordinate', 'string'),\n",
       " ('Y Coordinate', 'string'),\n",
       " ('Year', 'string'),\n",
       " ('Updated On', 'string'),\n",
       " ('Latitude', 'string'),\n",
       " ('Longitude', 'string'),\n",
       " ('Location', 'string')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_timestamp,col,lit\n",
    "\n",
    "rc = spark.read.csv(path,header=True).withColumn('Date',to_timestamp(col('Date'),'MM/dd/yyyy hh:mm:ss a'))\n",
    "rc.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PeeOFy5cgDRq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|               Date|\n",
      "+-------------------+\n",
      "|2022-04-05 12:00:00|\n",
      "|2022-12-11 20:21:00|\n",
      "|2022-12-30 23:00:00|\n",
      "|2022-12-18 11:00:00|\n",
      "|2022-12-21 17:25:00|\n",
      "|2022-12-31 01:01:00|\n",
      "|2022-02-13 11:31:00|\n",
      "|2022-04-07 00:00:00|\n",
      "|2022-11-23 02:00:00|\n",
      "|2022-11-30 15:00:00|\n",
      "|2022-12-18 05:30:00|\n",
      "|2022-12-21 01:00:00|\n",
      "|2022-12-21 16:00:00|\n",
      "|2022-12-01 08:00:00|\n",
      "|2022-05-11 03:00:00|\n",
      "|2022-02-02 09:00:00|\n",
      "|2022-09-02 02:00:00|\n",
      "|2022-10-27 14:37:00|\n",
      "|2022-11-27 19:00:00|\n",
      "|2022-07-09 02:30:00|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rc.select(\"Date\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qLS_NEpEgDBJ"
   },
   "outputs": [],
   "source": [
    "rc2=rc.filter(col('Date') >= lit('2022-12-01'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ugRDxNwNgHNa"
   },
   "outputs": [],
   "source": [
    "rc3 = rc2.withColumn('Date', to_date(col('Date'), 'MM/dd/yyyy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E7NuMVpygC2h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|      Date|\n",
      "+----------+\n",
      "|2022-12-01|\n",
      "|2022-12-02|\n",
      "|2022-12-03|\n",
      "|2022-12-04|\n",
      "|2022-12-05|\n",
      "|2022-12-06|\n",
      "|2022-12-07|\n",
      "|2022-12-08|\n",
      "|2022-12-09|\n",
      "|2022-12-10|\n",
      "|2022-12-11|\n",
      "|2022-12-12|\n",
      "|2022-12-13|\n",
      "|2022-12-14|\n",
      "|2022-12-15|\n",
      "|2022-12-16|\n",
      "|2022-12-17|\n",
      "|2022-12-18|\n",
      "|2022-12-19|\n",
      "|2022-12-20|\n",
      "|2022-12-21|\n",
      "|2022-12-22|\n",
      "|2022-12-23|\n",
      "|2022-12-24|\n",
      "|2022-12-25|\n",
      "|2022-12-26|\n",
      "|2022-12-27|\n",
      "|2022-12-28|\n",
      "|2022-12-29|\n",
      "|2022-12-30|\n",
      "|2022-12-31|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rc3.select(col('Date')).distinct().sort('Date').show(31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mI_zYOVpf2yK"
   },
   "source": [
    "## Schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T6w6-fN9gG_7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JkUF4yJFgG25"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o3IB6VxLgGYi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "schemas.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
